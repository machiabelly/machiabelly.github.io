"use strict";
import { NamedFunction2, ObjectNamedFunction5 } from "./_Base";
import { RenderPixelController, coreCursorToUv } from "../../core/render/renderPixel/RenderPixelController";
export class cursorToUv extends NamedFunction2 {
  static type() {
    return "cursorToUv";
  }
  func(cursor, target) {
    coreCursorToUv(cursor, target);
    return target;
  }
}
export class renderPixel extends ObjectNamedFunction5 {
  constructor() {
    super(...arguments);
    this._renderPixelController = new RenderPixelController();
  }
  // Note for this to work on iOS:
  // The materials used for picking should have their transparency OFF.
  // This could potentially be done automatically by traversing the scene first.
  // private _renderTarget: WebGLRenderTarget = new WebGLRenderTarget(1, 1, {
  // 	minFilter: LinearFilter,
  // 	magFilter: NearestFilter,
  // 	format: RGBAFormat,
  // 	type: FloatType,
  // });
  // private _renderScene = new Scene();
  // private _restoreContext: RestoreContext = {
  // 	object: {
  // 		parent: null,
  // 	},
  // 	// scene: {
  // 	// 	overrideMaterial: null,
  // 	// },
  // 	renderer: {
  // 		toneMapping: NoToneMapping,
  // 		outputColorSpace: NoColorSpace,
  // 	},
  // };
  // private _read = new Float32Array(4);
  // private _getDefaultCamera: getDefaultCamera | undefined;
  static type() {
    return "renderPixel";
  }
  func(object3D, material, camera, backgroundColor, uv, target) {
    this._renderPixelController.renderColor(this.scene, object3D, material, camera, backgroundColor, uv, target);
    return target;
  }
  // private _prepare(object3D: Object3D, material: Material | null, backgroundColor: Color, renderer: WebGLRenderer) {
  // 	// save context
  // 	this._restoreContext.renderer.outputColorSpace = renderer.outputColorSpace;
  // 	this._restoreContext.renderer.toneMapping = renderer.toneMapping;
  // 	this._restoreContext.object.parent = object3D.parent;
  // 	// set context
  // 	this._renderScene.background = backgroundColor;
  // 	this._renderScene.overrideMaterial = material || null;
  // 	this._renderScene.attach(object3D);
  // 	renderer.toneMapping = NoToneMapping;
  // 	renderer.outputColorSpace = NoColorSpace;
  // }
  // private _render(uv: Vector2, camera: Camera, renderer: WebGLRenderer, target: Vector4) {
  // 	(camera as any).setViewOffset(
  // 		renderer.domElement.width,
  // 		renderer.domElement.height,
  // 		uv.x * renderer.domElement.width,
  // 		uv.y * renderer.domElement.height,
  // 		1,
  // 		1
  // 	);
  // 	renderer.setRenderTarget(this._renderTarget);
  // 	renderer.clear();
  // 	renderer.render(this._renderScene, camera);
  // 	renderer.setRenderTarget(null);
  // 	(camera as any).clearViewOffset();
  // 	// There are some cases where .readRenderTargetPixels is slow,
  // 	// and this seems to be due to the calls to _gl.getParameters.
  // 	// Here we are bypassing it.
  // 	// Note: this attempt to bypass needs "properties", which is internal to WebGLRenderer.
  // 	// const context = renderer.getContext();
  // 	// const textureFormat = context.RGBA; // RGBAFormat see three/WebGLUtils.js
  // 	// const textureType = context.FLOAT; // FloatType see three/WebGLUtils.js
  // 	// context.readPixels(0, 0, 1, 1, textureFormat, textureType, this._read);
  // 	renderer.readRenderTargetPixels(this._renderTarget, 0, 0, 1, 1, this._read);
  // 	// read buffer into target vector
  // 	target.fromArray(this._read);
  // }
  // private _restore(object3D: Object3D, renderer: WebGLRenderer) {
  // 	renderer.outputColorSpace = this._restoreContext.renderer.outputColorSpace;
  // 	renderer.toneMapping = this._restoreContext.renderer.toneMapping;
  // 	this._restoreContext.object.parent?.attach(object3D);
  // }
}
